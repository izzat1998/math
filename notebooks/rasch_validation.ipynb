{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "j7kyye261pm",
   "source": "# Rasch Model (1PL IRT) Validation Study\n## Math Mock Exam Platform â€” Psychometric Validation\n\nThis notebook validates our Rasch model implementation by:\n1. Generating synthetic response data with **known** parameters\n2. Running calibration and checking **parameter recovery**\n3. Analyzing **Item Characteristic Curves** (ICCs)\n4. Computing **fit statistics** (infit/outfit)\n5. Testing **sample size sensitivity**\n6. Simulating a **realistic 55-item math exam**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "w9p2r80vucc",
   "source": "import sys, os\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom scipy import stats\n\n# Add backend to path\nsys.path.insert(0, os.path.join(os.path.dirname('__file__'), '..', 'backend'))\nfrom exams.rasch import rasch_probability, estimate_theta, estimate_item_difficulties, compute_item_fit\n\n# Plot style\nplt.style.use('seaborn-v0_8-whitegrid')\nmatplotlib.rcParams['figure.figsize'] = (12, 6)\nmatplotlib.rcParams['font.size'] = 12\n\nnp.random.seed(42)\nprint(\"All imports successful\")\nprint(f\"NumPy version: {np.__version__}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bvhlbu73dqh",
   "source": "## 1. Synthetic Data Generation\n\nWe generate response data from **known** item difficulties (beta) and student abilities (theta). If our calibration algorithm works correctly, it should **recover** these parameters.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "cx3hpsb6ttv",
   "source": "def generate_response_matrix(true_thetas, true_betas, seed=42):\n    \"\"\"Generate binary response matrix from known Rasch parameters.\n    \n    Args:\n        true_thetas: array of student abilities\n        true_betas: array of item difficulties\n        seed: random seed for reproducibility\n    \n    Returns:\n        N x J binary matrix where entry (i,j) = 1 if student i answered item j correctly\n    \"\"\"\n    rng = np.random.RandomState(seed)\n    N, J = len(true_thetas), len(true_betas)\n    matrix = np.zeros((N, J))\n    \n    for i in range(N):\n        for j in range(J):\n            p = rasch_probability(true_thetas[i], true_betas[j])\n            matrix[i, j] = 1.0 if rng.random() < p else 0.0\n    \n    # Summary\n    print(f\"Generated {N} students x {J} items response matrix\")\n    print(f\"Overall correct rate: {matrix.mean():.1%}\")\n    print(f\"True theta range: [{true_thetas.min():.2f}, {true_thetas.max():.2f}]\")\n    print(f\"True beta range: [{true_betas.min():.2f}, {true_betas.max():.2f}]\")\n    \n    return matrix\n\n# Quick test\ntest_matrix = generate_response_matrix(\n    np.array([0.0, 1.0, -1.0]),\n    np.array([-1.0, 0.0, 1.0]),\n    seed=42\n)\nprint(f\"\\nTest matrix:\\n{test_matrix}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "totez9x8lh8",
   "source": "## 2. Parameter Recovery\n\nThe most critical validation: can our JMLE algorithm recover the **true** item difficulties from response data?\n\nWe test at three scales:\n- **Small:** 20 students x 10 items\n- **Medium:** 100 students x 55 items (matching our exam)\n- **Large:** 1000 students x 55 items (production target)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3w3cxhjfu23",
   "source": "def run_recovery_analysis(N, J, true_beta_range=(-2.5, 2.5), theta_mean=0, theta_sd=1.0, seed=42):\n    \"\"\"Run parameter recovery analysis at given scale.\"\"\"\n    rng = np.random.RandomState(seed)\n    true_betas = np.linspace(true_beta_range[0], true_beta_range[1], J)\n    true_thetas = rng.normal(theta_mean, theta_sd, N)\n    \n    matrix = generate_response_matrix(true_thetas, true_betas, seed=seed)\n    est_betas, est_thetas = estimate_item_difficulties(matrix)\n    \n    # Center both for comparison (Rasch model is identified up to a constant)\n    true_centered = true_betas - true_betas.mean()\n    est_centered = est_betas - est_betas.mean()\n    \n    # Metrics\n    corr = np.corrcoef(true_centered, est_centered)[0, 1]\n    rmse = np.sqrt(np.mean((true_centered - est_centered) ** 2))\n    \n    return {\n        'true_betas': true_centered,\n        'est_betas': est_centered,\n        'true_thetas': true_thetas,\n        'est_thetas': est_thetas,\n        'corr': corr,\n        'rmse': rmse,\n        'N': N,\n        'J': J,\n        'matrix': matrix,\n    }\n\n# Run all three scales\nscales = [\n    (\"Small (20x10)\", 20, 10),\n    (\"Medium (100x55)\", 100, 55),\n    (\"Large (1000x55)\", 1000, 55),\n]\n\nresults = {}\nfor label, N, J in scales:\n    print(f\"\\n{'='*50}\")\n    print(f\"  {label}\")\n    print(f\"{'='*50}\")\n    r = run_recovery_analysis(N, J, seed=42)\n    results[label] = r\n    print(f\"  beta correlation: {r['corr']:.4f}\")\n    print(f\"  beta RMSE: {r['rmse']:.4f}\")\n\n# Plot all three\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\nfor ax, (label, r) in zip(axes, results.items()):\n    ax.scatter(r['true_betas'], r['est_betas'], alpha=0.7, edgecolors='navy', facecolors='cornflowerblue', s=60)\n    \n    # Perfect recovery line\n    lims = [min(r['true_betas'].min(), r['est_betas'].min()) - 0.3,\n            max(r['true_betas'].max(), r['est_betas'].max()) + 0.3]\n    ax.plot(lims, lims, 'r--', linewidth=2, label='Perfect recovery')\n    \n    ax.set_xlabel('True beta (item difficulty)', fontsize=11)\n    ax.set_ylabel('Estimated beta', fontsize=11)\n    ax.set_title(f'{label}\\nr = {r[\"corr\"]:.4f}, RMSE = {r[\"rmse\"]:.4f}', fontsize=12, fontweight='bold')\n    ax.legend()\n    ax.set_aspect('equal')\n    ax.set_xlim(lims)\n    ax.set_ylim(lims)\n\nplt.suptitle('Item Difficulty Parameter Recovery', fontsize=14, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.savefig('parameter_recovery.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\\nPlot saved as parameter_recovery.png\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "rw4y6q17w6r",
   "source": "## 3. Item Characteristic Curves (ICCs)\n\nICCs show the probability of a correct response as a function of student ability (theta) for each item. In the Rasch model, all ICCs have the same slope (discrimination = 1) but are shifted left/right by their difficulty (beta).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0um16kmfyyl",
   "source": "# Use the large-scale results for ICC plots\nr = results[\"Large (1000x55)\"]\nest_betas = r['est_betas']\n\n# Select representative items: easiest, 25th percentile, median, 75th, hardest\nindices = [0, len(est_betas)//4, len(est_betas)//2, 3*len(est_betas)//4, len(est_betas)-1]\nlabels = ['Easiest', 'Q1 (25th %ile)', 'Median', 'Q3 (75th %ile)', 'Hardest']\ncolors = ['#2ecc71', '#3498db', '#f39c12', '#e74c3c', '#8e44ad']\n\ntheta_range = np.linspace(-4, 4, 200)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Left: Selected ICCs\nfor idx, label, color in zip(indices, labels, colors):\n    probs = [rasch_probability(t, est_betas[idx]) for t in theta_range]\n    ax1.plot(theta_range, probs, color=color, linewidth=2.5, label=f'{label} (beta={est_betas[idx]:.2f})')\n    ax1.axhline(y=0.5, color='gray', linestyle=':', alpha=0.5)\n    ax1.axvline(x=est_betas[idx], color=color, linestyle='--', alpha=0.3)\n\nax1.set_xlabel('Student Ability (theta)', fontsize=12)\nax1.set_ylabel('P(Correct)', fontsize=12)\nax1.set_title('Item Characteristic Curves -- Selected Items', fontsize=13, fontweight='bold')\nax1.legend(loc='lower right', fontsize=10)\nax1.set_ylim(-0.02, 1.02)\n\n# Right: All ICCs overlaid (shows the family of curves)\nfor j in range(len(est_betas)):\n    probs = [rasch_probability(t, est_betas[j]) for t in theta_range]\n    ax2.plot(theta_range, probs, color='steelblue', alpha=0.15, linewidth=1)\n\n# Highlight the 5 selected ones\nfor idx, color in zip(indices, colors):\n    probs = [rasch_probability(t, est_betas[idx]) for t in theta_range]\n    ax2.plot(theta_range, probs, color=color, linewidth=2)\n\nax2.set_xlabel('Student Ability (theta)', fontsize=12)\nax2.set_ylabel('P(Correct)', fontsize=12)\nax2.set_title('All 55 Item Characteristic Curves', fontsize=13, fontweight='bold')\nax2.set_ylim(-0.02, 1.02)\n\nplt.tight_layout()\nplt.savefig('icc_curves.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"ICC curves saved as icc_curves.png\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3w2b3ps94r5",
   "source": "## 4. Fit Statistics\n\n**Infit** (information-weighted) and **Outfit** (outlier-sensitive) Mean Square statistics measure how well items conform to the Rasch model. \n\n- **Expected value:** 1.0 (perfect fit)\n- **Acceptable range:** 0.7 -- 1.3\n- **Degrading:** < 0.7 (overfit/redundant) or > 1.3 (underfit/noisy)\n- **Distorting:** > 2.0 (severe misfit)\n\nSince our data is generated FROM the Rasch model, all items should fit well.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "e1ehro03kz",
   "source": "r = results[\"Large (1000x55)\"]\nmatrix = r['matrix']\nest_betas = r['est_betas']\nest_thetas = r['est_thetas']\n\n# Compute fit for all items\nfit_data = []\nfor j in range(len(est_betas)):\n    fit = compute_item_fit(j, matrix, est_thetas, est_betas)\n    fit_data.append({\n        'item': j + 1,\n        'beta': est_betas[j],\n        'infit': fit['infit'],\n        'outfit': fit['outfit'],\n    })\n\ninfits = np.array([f['infit'] for f in fit_data])\noutfits = np.array([f['outfit'] for f in fit_data])\n\n# Summary\nprint(\"=\" * 60)\nprint(\"  FIT STATISTICS SUMMARY (1000 students x 55 items)\")\nprint(\"=\" * 60)\nprint(f\"\\n  Infit MNSQ:  mean = {infits.mean():.3f}, SD = {infits.std():.3f}\")\nprint(f\"               range = [{infits.min():.3f}, {infits.max():.3f}]\")\nprint(f\"\\n  Outfit MNSQ: mean = {outfits.mean():.3f}, SD = {outfits.std():.3f}\")\nprint(f\"               range = [{outfits.min():.3f}, {outfits.max():.3f}]\")\n\n# Flag misfitting items\nmisfit_infit = np.sum((infits < 0.7) | (infits > 1.3))\nmisfit_outfit = np.sum((outfits < 0.7) | (outfits > 1.3))\nprint(f\"\\n  Items with infit outside [0.7, 1.3]: {misfit_infit}/{len(infits)}\")\nprint(f\"  Items with outfit outside [0.7, 1.3]: {misfit_outfit}/{len(outfits)}\")\n\n# Plot\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Infit bar chart\nbars1 = ax1.bar(range(1, len(infits)+1), infits, color='steelblue', alpha=0.8, edgecolor='navy', linewidth=0.5)\nax1.axhline(y=1.0, color='green', linewidth=2, label='Expected (1.0)')\nax1.axhline(y=0.7, color='orange', linewidth=1.5, linestyle='--', label='Lower bound (0.7)')\nax1.axhline(y=1.3, color='orange', linewidth=1.5, linestyle='--', label='Upper bound (1.3)')\nax1.set_xlabel('Item Number', fontsize=11)\nax1.set_ylabel('Infit MNSQ', fontsize=11)\nax1.set_title('Infit Mean Square by Item', fontsize=13, fontweight='bold')\nax1.legend(fontsize=9)\n\n# Color misfitting bars\nfor i, (bar, val) in enumerate(zip(bars1, infits)):\n    if val < 0.7 or val > 1.3:\n        bar.set_color('red')\n        bar.set_alpha(0.9)\n\n# Outfit bar chart\nbars2 = ax2.bar(range(1, len(outfits)+1), outfits, color='steelblue', alpha=0.8, edgecolor='navy', linewidth=0.5)\nax2.axhline(y=1.0, color='green', linewidth=2, label='Expected (1.0)')\nax2.axhline(y=0.7, color='orange', linewidth=1.5, linestyle='--', label='Lower bound (0.7)')\nax2.axhline(y=1.3, color='orange', linewidth=1.5, linestyle='--', label='Upper bound (1.3)')\nax2.set_xlabel('Item Number', fontsize=11)\nax2.set_ylabel('Outfit MNSQ', fontsize=11)\nax2.set_title('Outfit Mean Square by Item', fontsize=13, fontweight='bold')\nax2.legend(fontsize=9)\n\nfor i, (bar, val) in enumerate(zip(bars2, outfits)):\n    if val < 0.7 or val > 1.3:\n        bar.set_color('red')\n        bar.set_alpha(0.9)\n\nplt.tight_layout()\nplt.savefig('fit_statistics.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"Fit statistics plot saved\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "26hw01ahyzi",
   "source": "## 5. Person Fit -- Student Ability Recovery\n\nCan we recover individual student abilities (theta)?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "5pk0bnxgwy",
   "source": "r = results[\"Large (1000x55)\"]\n\n# True vs estimated thetas\ntrue_t = r['true_thetas']\nest_t = r['est_thetas']\n\n# Center both\ntrue_t_c = true_t - true_t.mean()\nest_t_c = est_t - est_t.mean()\n\ncorr_theta = np.corrcoef(true_t_c, est_t_c)[0, 1]\nrmse_theta = np.sqrt(np.mean((true_t_c - est_t_c) ** 2))\n\nprint(\"=\" * 50)\nprint(\"  PERSON FIT (theta Recovery)\")\nprint(\"=\" * 50)\nprint(f\"  Correlation:  {corr_theta:.4f}\")\nprint(f\"  RMSE:         {rmse_theta:.4f}\")\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\n# Scatter\nax1.scatter(true_t_c, est_t_c, alpha=0.3, s=20, color='steelblue')\nlims = [-4, 4]\nax1.plot(lims, lims, 'r--', linewidth=2, label='Perfect recovery')\nax1.set_xlabel('True theta (student ability)', fontsize=11)\nax1.set_ylabel('Estimated theta', fontsize=11)\nax1.set_title(f'Student Ability Recovery\\nr = {corr_theta:.4f}, RMSE = {rmse_theta:.4f}', fontsize=13, fontweight='bold')\nax1.legend()\nax1.set_xlim(lims)\nax1.set_ylim(lims)\nax1.set_aspect('equal')\n\n# Error distribution\nerrors = est_t_c - true_t_c\nax2.hist(errors, bins=50, color='steelblue', edgecolor='navy', alpha=0.8, density=True)\nax2.axvline(x=0, color='red', linewidth=2, linestyle='--')\nax2.set_xlabel('Estimation Error (est - true)', fontsize=11)\nax2.set_ylabel('Density', fontsize=11)\nax2.set_title(f'theta Estimation Error Distribution\\nMean = {errors.mean():.3f}, SD = {errors.std():.3f}', fontsize=13, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('person_fit.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"Person fit plot saved\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "udthnpn0as",
   "source": "## 6. Sample Size Sensitivity\n\nHow many students do we need for accurate calibration? We test from N=30 to N=1000.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "zsw5d4an0mg",
   "source": "sample_sizes = [30, 50, 100, 200, 500, 1000]\nJ = 55  # items matching our exam\n\nbeta_rmses = []\nbeta_corrs = []\ntheta_rmses = []\n\nfor N in sample_sizes:\n    print(f\"Running N={N}...\", end=\" \")\n    r = run_recovery_analysis(N, J, seed=42)\n    beta_rmses.append(r['rmse'])\n    beta_corrs.append(r['corr'])\n    \n    # Theta RMSE\n    true_t = r['true_thetas'] - r['true_thetas'].mean()\n    est_t = r['est_thetas'] - r['est_thetas'].mean()\n    theta_rmses.append(np.sqrt(np.mean((true_t - est_t) ** 2)))\n    print(f\"beta RMSE={r['rmse']:.3f}, r={r['corr']:.4f}\")\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n\nax1.plot(sample_sizes, beta_rmses, 'o-', color='steelblue', linewidth=2.5, markersize=8)\nax1.set_xlabel('Number of Students (N)', fontsize=11)\nax1.set_ylabel('beta RMSE', fontsize=11)\nax1.set_title('Item Difficulty RMSE vs Sample Size', fontsize=13, fontweight='bold')\nax1.set_xscale('log')\nax1.axhline(y=0.2, color='green', linestyle='--', alpha=0.5, label='Target: 0.2')\nax1.legend()\n\nax2.plot(sample_sizes, beta_corrs, 'o-', color='#e74c3c', linewidth=2.5, markersize=8)\nax2.set_xlabel('Number of Students (N)', fontsize=11)\nax2.set_ylabel('Correlation (r)', fontsize=11)\nax2.set_title('beta Recovery Correlation vs Sample Size', fontsize=13, fontweight='bold')\nax2.set_xscale('log')\nax2.set_ylim(0.8, 1.01)\nax2.axhline(y=0.99, color='green', linestyle='--', alpha=0.5, label='Target: 0.99')\nax2.legend()\n\nax3.plot(sample_sizes, theta_rmses, 'o-', color='#2ecc71', linewidth=2.5, markersize=8)\nax3.set_xlabel('Number of Students (N)', fontsize=11)\nax3.set_ylabel('theta RMSE', fontsize=11)\nax3.set_title('Person Ability RMSE vs Sample Size', fontsize=13, fontweight='bold')\nax3.set_xscale('log')\n\nplt.suptitle('Sample Size Sensitivity Analysis', fontsize=14, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.savefig('sample_size_analysis.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(\"\\nSample size analysis complete\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "iagc2ui39f",
   "source": "## 7. Realistic Math Exam Simulation\n\nSimulating a realistic 55-item math exam with:\n- Items 1--35: Single answer (varied difficulty)\n- Items 36--45: Paired (a+b) questions\n- Student abilities: theta ~ N(0, 1) representing a typical test population\n- Item difficulties: beta distributed to match a real exam curve",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "b9ed8s95co",
   "source": "np.random.seed(42)\n\n# Realistic item difficulty distribution for a math exam\n# Easy questions at start, harder at end, paired questions are harder\nsingle_betas = np.concatenate([\n    np.random.normal(-1.5, 0.3, 10),   # Q1-10: Easy\n    np.random.normal(-0.5, 0.4, 10),   # Q11-20: Medium-easy\n    np.random.normal(0.5, 0.4, 10),    # Q21-30: Medium-hard\n    np.random.normal(1.5, 0.3, 5),     # Q31-35: Hard\n])\n\n# Paired questions (a and b parts) -- generally harder\npaired_betas = np.concatenate([\n    np.random.normal(1.0, 0.4, 10),    # Q36-45 part a: Hard\n    np.random.normal(1.5, 0.5, 10),    # Q36-45 part b: Harder\n])\n\ntrue_betas = np.concatenate([single_betas, paired_betas])\nprint(f\"Total items: {len(true_betas)} (35 single + 20 paired parts)\")\n\n# 500 students with realistic ability distribution\ntrue_thetas = np.random.normal(0.0, 1.0, 500)\n\n# Generate responses\nmatrix = generate_response_matrix(true_thetas, true_betas, seed=42)\n\n# Run calibration\nest_betas, est_thetas = estimate_item_difficulties(matrix)\n\n# Center both\ntrue_c = true_betas - true_betas.mean()\nest_c = est_betas - est_betas.mean()\n\ncorr = np.corrcoef(true_c, est_c)[0, 1]\nrmse = np.sqrt(np.mean((true_c - est_c) ** 2))\n\nprint(f\"\\nRealistic Exam Calibration Results:\")\nprint(f\"  beta correlation: {corr:.4f}\")\nprint(f\"  beta RMSE: {rmse:.4f}\")\n\n# Detailed breakdown\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n# 1. Beta recovery scatter\nax = axes[0, 0]\n# Color by question type\nax.scatter(true_c[:35], est_c[:35], alpha=0.7, color='#3498db', s=60, label='Single (Q1-35)', edgecolors='navy')\nax.scatter(true_c[35:45], est_c[35:45], alpha=0.7, color='#e74c3c', s=60, label='Paired-a (Q36-45a)', edgecolors='darkred', marker='s')\nax.scatter(true_c[45:], est_c[45:], alpha=0.7, color='#e67e22', s=60, label='Paired-b (Q36-45b)', edgecolors='saddlebrown', marker='^')\nlims = [min(true_c.min(), est_c.min()) - 0.3, max(true_c.max(), est_c.max()) + 0.3]\nax.plot(lims, lims, 'k--', linewidth=2, alpha=0.5)\nax.set_xlabel('True beta')\nax.set_ylabel('Estimated beta')\nax.set_title(f'Item Difficulty Recovery\\nr = {corr:.4f}, RMSE = {rmse:.4f}', fontweight='bold')\nax.legend()\n\n# 2. Difficulty distribution\nax = axes[0, 1]\nax.hist(est_c[:35], bins=15, alpha=0.6, color='#3498db', label='Single items', edgecolor='navy')\nax.hist(est_c[35:], bins=10, alpha=0.6, color='#e74c3c', label='Paired items', edgecolor='darkred')\nax.set_xlabel('Estimated beta')\nax.set_ylabel('Count')\nax.set_title('Item Difficulty Distribution', fontweight='bold')\nax.legend()\n\n# 3. Score distribution\nraw_scores = matrix.sum(axis=1)\nax = axes[1, 0]\nax.hist(raw_scores, bins=30, color='steelblue', edgecolor='navy', alpha=0.8)\nax.axvline(x=raw_scores.mean(), color='red', linewidth=2, linestyle='--', label=f'Mean = {raw_scores.mean():.1f}')\nax.set_xlabel('Raw Score (out of 55)')\nax.set_ylabel('Count')\nax.set_title(f'Score Distribution (N=500)\\nMean={raw_scores.mean():.1f}, SD={raw_scores.std():.1f}', fontweight='bold')\nax.legend()\n\n# 4. Theta vs raw score\nax = axes[1, 1]\nax.scatter(raw_scores, est_thetas, alpha=0.3, s=15, color='steelblue')\nax.set_xlabel('Raw Score')\nax.set_ylabel('Estimated theta (ability)')\nax.set_title('Raw Score vs Rasch Ability Estimate', fontweight='bold')\n# Add nonlinear relationship annotation\nz = np.polyfit(raw_scores, est_thetas, 3)\np = np.poly1d(z)\nx_smooth = np.linspace(raw_scores.min(), raw_scores.max(), 100)\nax.plot(x_smooth, p(x_smooth), 'r-', linewidth=2, label='Cubic fit')\nax.legend()\n\nplt.suptitle('Realistic 55-Item Math Exam Simulation', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig('realistic_exam_simulation.png', dpi=150, bbox_inches='tight')\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "922k0loit4g",
   "source": "## 8. Validation Summary",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "eikwnqdhkis",
   "source": "print(\"=\" * 65)\nprint(\"  RASCH MODEL VALIDATION -- SUMMARY REPORT\")\nprint(\"=\" * 65)\n\nprint(\"\\n  1. PARAMETER RECOVERY\")\nprint(\"  \" + \"-\" * 55)\nfor label, r in results.items():\n    status = \"PASS\" if r['corr'] > 0.95 else \"FAIL\"\n    print(f\"    {label:25s}  r = {r['corr']:.4f}  RMSE = {r['rmse']:.4f}  {status}\")\n\nprint(f\"\\n    {'Realistic Exam (500x55)':25s}  r = {corr:.4f}  RMSE = {rmse:.4f}  {'PASS' if corr > 0.95 else 'FAIL'}\")\n\nprint(\"\\n  2. FIT STATISTICS (Large Scale)\")\nprint(\"  \" + \"-\" * 55)\nprint(f\"    Infit MNSQ:  {infits.mean():.3f} +/- {infits.std():.3f}\")\nprint(f\"    Outfit MNSQ: {outfits.mean():.3f} +/- {outfits.std():.3f}\")\nitems_in_range = np.sum((infits >= 0.7) & (infits <= 1.3))\nprint(f\"    Items in acceptable range: {items_in_range}/{len(infits)} ({items_in_range/len(infits)*100:.0f}%)\")\nfit_status = \"PASS\" if items_in_range / len(infits) > 0.90 else \"FAIL\"\nprint(f\"    Status: {fit_status}\")\n\nprint(\"\\n  3. PERSON FIT\")\nprint(\"  \" + \"-\" * 55)\nprint(f\"    theta correlation:  {corr_theta:.4f}\")\nprint(f\"    theta RMSE:         {rmse_theta:.4f}\")\nperson_status = \"PASS\" if corr_theta > 0.90 else \"FAIL\"\nprint(f\"    Status: {person_status}\")\n\nprint(\"\\n  4. SAMPLE SIZE RECOMMENDATION\")\nprint(\"  \" + \"-\" * 55)\nfor n, rmse_val, corr_val in zip(sample_sizes, beta_rmses, beta_corrs):\n    marker = \" <-- recommended minimum\" if n == 200 else \"\"\n    print(f\"    N = {n:5d}:  RMSE = {rmse_val:.3f},  r = {corr_val:.4f}{marker}\")\n\nprint(\"\\n\" + \"=\" * 65)\nall_pass = (corr > 0.95) and (items_in_range / len(infits) > 0.90) and (corr_theta > 0.90)\nif all_pass:\n    print(\"  OVERALL: MODEL VALIDATED -- Ready for production with N >= 200\")\nelse:\n    print(\"  OVERALL: VALIDATION ISSUES FOUND -- Review above\")\nprint(\"=\" * 65)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}